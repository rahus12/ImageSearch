{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce17704",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a06c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rahul Sampagaon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f495d685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasLazyLoader (keras_2) keras.api._v2.keras as keras mode=None>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bacd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from deepface import DeepFace\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c9eb3",
   "metadata": {},
   "source": [
    "# Required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f68a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./Dataset_cropped_MLclass\"  # change this as needed\n",
    "MODEL_NAME = \"Facenet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448bcb8",
   "metadata": {},
   "source": [
    "Lists to hold the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f9d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "labels = []\n",
    "# Count total images for progress bar\n",
    "all_image_paths = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146349a4",
   "metadata": {},
   "source": [
    "## load all the images from the folders and generate embeddings\n",
    "the folder structure is given by:\n",
    "\n",
    "|- person1  \n",
    "|---- img1  \n",
    "|---- img2  \n",
    "|- person2  \n",
    "|----- img1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_embeddings(dataset_path, model_name=\"Facenet\", generate_embeddings=True) -> dict:\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    embeddings = []\n",
    "\n",
    "    for person_name in os.listdir(dataset_path):\n",
    "        person_folder = os.path.join(dataset_path, person_name)\n",
    "        if not os.path.isdir(person_folder):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(person_folder):\n",
    "            if img_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                img_path = os.path.join(person_folder, img_name)\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(person_name)\n",
    "                filenames.append(img_name)\n",
    "\n",
    "    if generate_embeddings:\n",
    "        for img_path in tqdm(image_paths, desc=\"Generating Embeddings\"):\n",
    "            try:\n",
    "                result = DeepFace.represent(\n",
    "                    img_path=img_path,\n",
    "                    model_name=model_name,\n",
    "                    enforce_detection=False\n",
    "                )[0]\n",
    "                embeddings.append(result[\"embedding\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {img_path}: {e}\")\n",
    "                embeddings.append(None)  # to keep alignment\n",
    "\n",
    "    return {\n",
    "        \"paths\": image_paths,\n",
    "        \"labels\": labels,\n",
    "        \"filenames\": filenames,\n",
    "        \"embeddings\": embeddings if generate_embeddings else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a520eea",
   "metadata": {},
   "source": [
    "# What DeepFace does automatically:\n",
    "- Face Detection: Uses OpenCV, RetinaFace, or MTCNN to find the face in the image.\n",
    "\n",
    "- Face Alignment: Aligns the detected face by rotating and centering based on eye/mouth positions.\n",
    "\n",
    "- Image Resizing: Resizes the face to the exact input size required by the selected model (e.g., 160×160 for Facenet, 112×112 for ArcFace).\n",
    "\n",
    "- Normalization & Tensor Conversion: Converts the image to the proper format (e.g., pixel value scaling, tensor dtype, channel ordering).\n",
    "\n",
    "- Model Inference: Passes the processed face through the model to get the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ceb255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 1180/1180 [08:03<00:00,  2.44it/s]\n"
     ]
    }
   ],
   "source": [
    "#usage\n",
    "\n",
    "data = load_images_and_embeddings(DATASET_PATH, model_name=\"Facenet\", generate_embeddings=True)\n",
    "\n",
    "# Access results\n",
    "image_paths = data[\"paths\"]\n",
    "labels = data[\"labels\"]\n",
    "filenames = data[\"filenames\"]\n",
    "embeddings = data[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e021764",
   "metadata": {},
   "source": [
    "# Save and load the Embeddings and labels for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f05eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"embeddings.npy\", np.array(embeddings))\n",
    "np.save(\"labels.npy\", np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6f7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('embeddings.npy')\n",
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3707ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure embeddings are float32\n",
    "embedding_matrix = np.array(embeddings).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ebbc9",
   "metadata": {},
   "source": [
    "### The shape is given by (number of images , dimension returned by facenet)  \n",
    "which is (1180, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2ffcdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1180, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e32178",
   "metadata": {},
   "source": [
    "# Create the Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42fa3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index (cosine similarity via inner product on normalized vectors)\n",
    "dimension = embedding_matrix.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # IP = inner product\n",
    "faiss.normalize_L2(embedding_matrix)  # normalize vectors for cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7c018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0ccbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"face_index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d19813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('face_index.faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daafb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of tuples\n",
    "# tuple has (label, file_path, similarity score)\n",
    "def search_similar_faces(img_path, k=5) -> list[tuple]:\n",
    "    try:\n",
    "        # Step 1: Generate embedding from image\n",
    "        result = DeepFace.represent(\n",
    "            img_path=img_path,\n",
    "            model_name=MODEL_NAME,\n",
    "            enforce_detection=False\n",
    "        )[0]\n",
    "\n",
    "        query_vector = np.array([result[\"embedding\"]]).astype(\"float32\")\n",
    "        faiss.normalize_L2(query_vector)\n",
    "\n",
    "        # Step 2: Search in FAISS\n",
    "        distances, indices = index.search(query_vector, k)\n",
    "\n",
    "        # Step 3: Get results\n",
    "        results = []\n",
    "        for i in range(k):\n",
    "            idx = indices[0][i]\n",
    "            sim = distances[0][i]\n",
    "            # label = metadata[idx][\"label\"]\n",
    "            label = labels[idx]\n",
    "            # file_path = metadata[idx][\"file\"]\n",
    "            file_path = image_paths[idx]\n",
    "            results.append((label, file_path, sim))\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a921f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: xxxx"
     ]
    }
   ],
   "source": [
    "# query_image = \"harshimage.jpg\"\n",
    "query_image = '0220_18.jpeg'\n",
    "matches = search_similar_faces(query_image, k=1)\n",
    "\n",
    "for label, filepath, similarity in matches:\n",
    "    print(f\"Matched: {label} | File: {filepath} | Similarity: {similarity:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
